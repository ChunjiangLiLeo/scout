# ğŸ  Address Matching Pipeline (Scout Project)

A scalable, modular Python pipeline for high-volume address matching using PostgreSQL, fuzzy logic, blocking strategies, and fallback mechanisms.

This project was built as part of the **Scout Matching System**, designed to match parsed transaction addresses against a canonical address database with high accuracy and performanceâ€”even at scale (100Kâ€“200M rows).

---

## ğŸ“¦ Features

## ğŸ” Matching Logic Overview

The address matching system is designed for accuracy, modularity, and scalability. The pipeline includes:

---

### Exact Match

- Performs a full-field join on:  
  `street_number + street_name + street_type + parsed_unit`
- If **all corresponding columns** in the transaction and address tables **match exactly**, the records are linked automatically.
- This ensures high-confidence matches without additional computation.

---

### Fuzzy Matching

- Uses `RapidFuzz` with `token_sort_ratio` scorer for approximate string comparison.
- Implements a **blocking strategy** by grouping on `street_name`, significantly reducing pairwise comparisons.
- A **similarity threshold of 80%** is applied â€” if a transaction record and a candidate address row exceed this score, they are joined.
- This allows for matching "Main Street" with "Main St", or typos like "Baker Ave." with "Bakker Avenue".

---

### Fallback Logic

If records remain unmatched after exact + fuzzy matching, a fallback matching stage is triggered:

- **Soundex Matching**:  
  Uses phonetic representation of street names (e.g., "Smith" â‰ˆ "Smyth") to identify potential matches.
- **Trigram Similarity**:  
  Computes token-level trigram overlaps on normalized full address strings. Matches exceeding 0.80 similarity are retained.

---

### Scalability-Ready

- Pipeline was successfully tested with up to **100,000 rows** on a constrained local environment.
- The architecture is designed to scale to **200 million rows or more** using:
  - Pandas vectorized operations
  - Batched I/O with PostgreSQL
  - Blocking to avoid `O(nÂ²)` fuzzy match explosion

---

## ğŸ§± Project Structure

```text
scout/
â”œâ”€â”€ schema/
â”‚   â””â”€â”€ init_schema.sql
â”‚       â†’ Manual schema definition (CREATE TABLE / FOREIGN KEY) for PostgreSQL setup

â”œâ”€â”€ msimulation.py
â”‚   â†’ Generate a synthetic 100,000-row transaction dataset based on seed data

â”œâ”€â”€ run_pipeline.py
â”‚   â†’ Optional script to execute the full matching + fallback process using environment-based table switching

â”œâ”€â”€ Scripts/
â”‚
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ ingest.py
â”‚   â”‚   â”‚   â†’ Load original CSV or source files into PostgreSQL
â”‚   â”‚   â”œâ”€â”€ ingest.ipynb
â”‚   â”‚   â”‚   â†’ Interactive ingestion via Jupyter (manual exploration)
â”‚   â”‚   â””â”€â”€ address.ipynb
â”‚   â”‚       â†’ Visual validation and sanity checks for canonical address list
â”‚
â”‚   â”œâ”€â”€ parseandjoin/
â”‚   â”‚   â”œâ”€â”€ parse.py
â”‚   â”‚   â”‚   â†’ Parse raw full_address strings into structured components using `usaddress`
â”‚   â”‚   â”œâ”€â”€ join.py
â”‚   â”‚   â”‚   â†’ Exact + Fuzzy (blocking) matcher using RapidFuzz and token_sort_ratio
â”‚   â”‚   â”œâ”€â”€ fallback.py
â”‚   â”‚   â”‚   â†’ Fallback matcher using Soundex phonetic matching and Trigram similarity
â”‚   â”‚   â””â”€â”€ runpipeline.py
â”‚   â”‚       â†’ (Legacy/alternate) orchestration for parse â†’ match â†’ fallback
â”‚
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â””â”€â”€ visualization.ipynb
â”‚   â”‚       â†’ Match statistics, memory/runtime visualization, success breakdowns
â”‚
â”‚   â”œâ”€â”€ filter/
â”‚   â”‚   â”œâ”€â”€ distinct.py
â”‚   â”‚   â”‚   â†’ Remove duplicate records from input transaction data
â”‚   â”‚   â”œâ”€â”€ duplicate.py
â”‚   â”‚   â”‚   â†’ Check for address collisions and repeated rows
â”‚   â”‚   â””â”€â”€ unmatched.py
â”‚   â”‚       â†’ Export and analyze unmatched transactions post-matching
â”‚
â”œâ”€â”€ Reports/
â”‚   â””â”€â”€ scalability_report_100k.md
â”‚       â†’ Analysis of performance results for 100K sample test: runtime, memory, accuracy

â”œâ”€â”€ requirements.txt
â”‚   â†’ Python dependency list (pandas, sqlalchemy, rapidfuzz, usaddress, etc.)

â””â”€â”€ README.md
    â†’ Project setup, structure, usage, performance, design decisions

